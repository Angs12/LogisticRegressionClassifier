{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":92791,"databundleVersionId":11083833,"sourceType":"competition"},{"sourceId":10813220,"sourceType":"datasetVersion","datasetId":6709477}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nltk\n\ncsv_data = pd.read_csv(\"/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/train_dataset.csv\")\n\narr = csv_data.to_numpy()\n\ndef preprocess_data(arr):\n    link_user_regex = re.compile(r'(@\\w*)|(https?://(\\w|[./])*)\\s*') #remove links and usernames\n    remove_symbols_regex = re.compile(r'[|{}_,/.\\'\\\"`<>!\\\\@#$%^&\\(\\)*\\-=\\+/?;:~\\[\\]]+') #remove symbols\n    remove_numbers_regex = re.compile(r'[0-9]+') #remove numbers\n    not_ascii_regex = re.compile('[^ -~]') #remove non ascii chars\n    for i in range(len(arr)):\n        row = arr[i]\n        row[1] = link_user_regex.sub(\"\",row[1])\n        row[1] = remove_symbols_regex.sub(\" \",row[1])\n        row[1] = not_ascii_regex.sub(\"\",row[1])\n        row[1] = remove_numbers_regex.sub(\"\",row[1])\n        row[1] = row[1].lower()\n        arr[i] = row\n    return arr\n\ndef remove_stopwords(arr):\n    stopwords_file = \"/kaggle/input/eng-stopwords/stop_words_english.txt\"\n    stopwords = open(stopwords_file,\"r\")\n    stopwords = stopwords.read().splitlines()\n    regex = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\n    for i in range(len(arr)):\n        row = arr[i]\n        row[1] = regex.sub(\"\",row[1])\n        arr[i] = row\n    return arr\n\ndef stemmer(arr):\n    stemmer = nltk.stem.PorterStemmer()\n    for i in range(len(arr)):\n        row = arr[i]\n        sentence = []\n        for word in row[1].split():\n            sentence.append(stemmer.stem(word))\n        row[1] = \" \".join(sentence)\n        arr[i] = row\n    return arr\n\narr = preprocess_data(arr)\narr = remove_stopwords(arr)\narr = stemmer(arr)\n\npos_count = 0\nfor i in range(len(arr)):\n    pos_count += arr[i][2]\n\nL = []\nfor i in range(len(arr)):\n    L += arr[i][1].split()\nwords = np.array(L)\n\n(words,counts) = np.unique(words,return_counts=True)\npop_words = sorted(list(zip(words,counts)),key= lambda tuple: tuple[1])\nwords,counts = zip(*pop_words[-10:])\n\nplt.figure()\nplt.bar(words,counts)\nplt.title(\"Popular Words\")\nplt.xlabel(\"Words\")\nplt.ylabel(\"Count\")\nplt.savefig(\"/kaggle/working/pop_words.png\")\n\nneg_count = len(arr) - pos_count\nplt.figure()\nplt.bar([\"Negative\",\"Positive\"],[neg_count,pos_count])\nplt.title(\"Sentiment Count\")\nplt.xlabel(\"Sentiment\")\nplt.ylabel(\"Count\")\nplt.savefig(\"/kaggle/working/sentiment_count.png\")","metadata":{"_uuid":"5ac2031c-358b-48bd-bb62-b81acd82c8c6","_cell_guid":"8673f056-20fc-4862-86bc-4091efba2d6d","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-24T11:40:03.981223Z","iopub.execute_input":"2025-02-24T11:40:03.981587Z","iopub.status.idle":"2025-02-24T11:40:33.380593Z","shell.execute_reply.started":"2025-02-24T11:40:03.981560Z","shell.execute_reply":"2025-02-24T11:40:33.379422Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score,precision_score,recall_score,accuracy_score\nimport sklearn.metrics\nimport pandas as pd\nimport numpy as np\n\ntrain_data = pd.read_csv(\"/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/train_dataset.csv\")\nval_data = pd.read_csv(\"/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/val_dataset.csv\")\n\ndef load_data(data):\n    arr = data.to_numpy()\n    arr = preprocess_data(arr)\n    arr = remove_stopwords(arr)\n    arr = stemmer(arr)\n    return arr\n\ndef create_input(vectorizer,data):\n    tweets = data[:,1]\n    gold_labels = data[:,2]\n    gold_labels = gold_labels.astype('int')\n    features = vectorizer.transform(tweets)\n    return (features,gold_labels)\n\ndef vectorize_input(vectorizer,data):\n    tweets = data[:,1]\n    features = vectorizer.transform(tweets)\n    return features\n\ndef train_model(vectorizer,data):\n    tweets = data[:,1]\n    gold_labels = data[:,2]\n    gold_labels = gold_labels.astype('int')\n    features = vectorizer.fit_transform(tweets)\n    clf = LogisticRegression(random_state=0).fit(features, gold_labels)\n    return clf\n                  \ntrain = load_data(train_data)\nval = load_data(val_data)\n\nvectorizer = TfidfVectorizer()\nclf = train_model(vectorizer,train)\n\nfeatures_val,val_gold_labels = create_input(vectorizer,val)\n\n\npred_labels = clf.predict(features_val)\n\nprint(\"F1: \",f1_score(val_gold_labels,pred_labels))\nprint(\"Accuracy: \",accuracy_score(val_gold_labels,pred_labels))\nprint(\"Precision: \",precision_score(val_gold_labels,pred_labels))\nprint(\"Recall: \",recall_score(val_gold_labels,pred_labels))\n","metadata":{"_uuid":"5d327e13-e85d-4e54-832f-3b211e4786c9","_cell_guid":"fd5d3d66-f8d2-4d2a-9d0f-5e7110766b7c","trusted":true,"collapsed":false,"execution":{"iopub.status.busy":"2025-02-24T11:56:21.483996Z","iopub.execute_input":"2025-02-24T11:56:21.484385Z","iopub.status.idle":"2025-02-24T11:56:58.021023Z","shell.execute_reply.started":"2025-02-24T11:56:21.484353Z","shell.execute_reply":"2025-02-24T11:56:58.019670Z"},"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/train_dataset.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/ai-2-deep-learning-for-nlp-homework-1/test_dataset.csv\")\n\ntrain = load_data(train_data)\ntest = load_data(test_data)\n\nvectorizer = TfidfVectorizer()\n\nclf = train_model(vectorizer,train)\ntest_features = vectorize_input(vectorizer,test)\n\npred_labels = clf.predict(test_features)\n\nL = []\nfor i in range(len(pred_labels)):\n    L.append([test[i,0],pred_labels[i]])\n\narr = np.array(L)\ncolumns = ['ID','Label']\ndataframe = pd.DataFrame(data=arr,columns=columns)\n\ndataframe.to_csv(\"/kaggle/working/submission.csv\",index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-24T12:07:51.788436Z","iopub.execute_input":"2025-02-24T12:07:51.788822Z","iopub.status.idle":"2025-02-24T12:08:24.493177Z","shell.execute_reply.started":"2025-02-24T12:07:51.788794Z","shell.execute_reply":"2025-02-24T12:08:24.491998Z"}},"outputs":[],"execution_count":null}]}